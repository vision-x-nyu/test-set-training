{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3339eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e064884b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>domain</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>url</th>\n",
       "      <th>videoID</th>\n",
       "      <th>question_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>short</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Humanity &amp; History</td>\n",
       "      <td>https://www.youtube.com/watch?v=fFjv93ACGo8</td>\n",
       "      <td>fFjv93ACGo8</td>\n",
       "      <td>001-1</td>\n",
       "      <td>Counting Problem</td>\n",
       "      <td>When demonstrating the Germany modern Christma...</td>\n",
       "      <td>[A. Apples., B. Candles., C. Berries., D. The ...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>short</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Humanity &amp; History</td>\n",
       "      <td>https://www.youtube.com/watch?v=fFjv93ACGo8</td>\n",
       "      <td>fFjv93ACGo8</td>\n",
       "      <td>001-2</td>\n",
       "      <td>Information Synopsis</td>\n",
       "      <td>What is the genre of this video?</td>\n",
       "      <td>[A. It is a news report that introduces the hi...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>short</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Humanity &amp; History</td>\n",
       "      <td>https://www.youtube.com/watch?v=fFjv93ACGo8</td>\n",
       "      <td>fFjv93ACGo8</td>\n",
       "      <td>001-3</td>\n",
       "      <td>Counting Problem</td>\n",
       "      <td>How many red socks are above the fireplace at ...</td>\n",
       "      <td>[A. 1., B. 4., C. 2., D. 3.]</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002</td>\n",
       "      <td>short</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Humanity &amp; History</td>\n",
       "      <td>https://www.youtube.com/watch?v=N1cdUjctpG8</td>\n",
       "      <td>N1cdUjctpG8</td>\n",
       "      <td>002-1</td>\n",
       "      <td>Object Recognition</td>\n",
       "      <td>Which of the following features/items is not d...</td>\n",
       "      <td>[A. Inkstone., B. Niche., C. Jade., D. Sacrifi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002</td>\n",
       "      <td>short</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Humanity &amp; History</td>\n",
       "      <td>https://www.youtube.com/watch?v=N1cdUjctpG8</td>\n",
       "      <td>N1cdUjctpG8</td>\n",
       "      <td>002-2</td>\n",
       "      <td>Action Reasoning</td>\n",
       "      <td>Which of the following reasons motivated the a...</td>\n",
       "      <td>[A. Because it's from Ming Dynasty and of spec...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id duration     domain        sub_category  \\\n",
       "0      001    short  Knowledge  Humanity & History   \n",
       "1      001    short  Knowledge  Humanity & History   \n",
       "2      001    short  Knowledge  Humanity & History   \n",
       "3      002    short  Knowledge  Humanity & History   \n",
       "4      002    short  Knowledge  Humanity & History   \n",
       "\n",
       "                                           url      videoID question_id  \\\n",
       "0  https://www.youtube.com/watch?v=fFjv93ACGo8  fFjv93ACGo8       001-1   \n",
       "1  https://www.youtube.com/watch?v=fFjv93ACGo8  fFjv93ACGo8       001-2   \n",
       "2  https://www.youtube.com/watch?v=fFjv93ACGo8  fFjv93ACGo8       001-3   \n",
       "3  https://www.youtube.com/watch?v=N1cdUjctpG8  N1cdUjctpG8       002-1   \n",
       "4  https://www.youtube.com/watch?v=N1cdUjctpG8  N1cdUjctpG8       002-2   \n",
       "\n",
       "              task_type                                           question  \\\n",
       "0      Counting Problem  When demonstrating the Germany modern Christma...   \n",
       "1  Information Synopsis                   What is the genre of this video?   \n",
       "2      Counting Problem  How many red socks are above the fireplace at ...   \n",
       "3    Object Recognition  Which of the following features/items is not d...   \n",
       "4      Action Reasoning  Which of the following reasons motivated the a...   \n",
       "\n",
       "                                             options answer  \n",
       "0  [A. Apples., B. Candles., C. Berries., D. The ...      C  \n",
       "1  [A. It is a news report that introduces the hi...      A  \n",
       "2                       [A. 1., B. 4., C. 2., D. 3.]      D  \n",
       "3  [A. Inkstone., B. Niche., C. Jade., D. Sacrifi...      C  \n",
       "4  [A. Because it's from Ming Dynasty and of spec...      D  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_mme = load_dataset(\"lmms-lab/Video-MME\")\n",
    "df = video_mme[\"test\"].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7636701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: {\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"from\": \"human\",\n",
      "      \"value\": \"When demonstrating the Germany modern Christmas tree is initially decorated with apples, candles and berries, which kind of the decoration has the largest number?\\nOptions:\\nA. Apples.\\nB. Candles.\\nC. Berries.\\nD. The three kinds are of the same number.\\nAnswer with the option's letter from the given choices directly.\"\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"gpt\",\n",
      "      \"value\": \"C\"\n",
      "    }\n",
      "  ],\n",
      "  \"extras\": {\n",
      "    \"idx\": 0\n",
      "  }\n",
      "}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Extras: {'idx': 0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m[Q]\u001b[0m When demonstrating the Germany modern Christmas tree is initially decorated with apples, candles and berries, which kind of the decoration has the largest number?\n",
      "Options:\n",
      "A. Apples.\n",
      "B. Candles.\n",
      "C. Berries.\n",
      "D. The three kinds are of the same number.\n",
      "Answer with the option's letter from the given choices directly.\n",
      "\u001b[1m[A]\u001b[0m C\n"
     ]
    }
   ],
   "source": [
    "def parse_options(options_str):\n",
    "    import re\n",
    "\n",
    "    if isinstance(options_str, list):\n",
    "        # Already a list\n",
    "        return options_str\n",
    "\n",
    "    if not isinstance(options_str, str):\n",
    "        raise ValueError(f\"Input must be a string or list, got {type(options_str)}\")\n",
    "\n",
    "    # Remove leading/trailing whitespace and brackets\n",
    "    s = options_str.strip()\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        s = s[1:-1].strip()\n",
    "\n",
    "    # Try to split by newlines if present\n",
    "    if \"\\n\" in s:\n",
    "        # Remove empty lines and strip each line\n",
    "        lines = [line.strip() for line in s.splitlines() if line.strip()]\n",
    "        # Remove trailing commas\n",
    "        lines = [line.rstrip(\",\") for line in lines]\n",
    "        # Remove enclosing quotes if present\n",
    "        lines = [line.strip('\"').strip(\"'\") for line in lines]\n",
    "        # Remove empty lines again\n",
    "        lines = [line for line in lines if line]\n",
    "        # If each line looks like an option (starts with e.g. \"A.\" or \"A:\"), return as is\n",
    "        if all(re.match(r\"^[A-Da-d][\\.\\:]\", line) for line in lines):\n",
    "            return lines\n",
    "        # Otherwise, try to join and split by comma\n",
    "        s = \" \".join(lines)\n",
    "\n",
    "    # Now split by comma, but only at top level (not inside brackets)\n",
    "    # This regex splits on commas that are followed by a space and a capital letter (option start)\n",
    "    parts = re.split(r\",\\s*(?=[A-Da-d][\\.\\:])\", s)\n",
    "    # Remove any extra whitespace and trailing commas\n",
    "    parts = [part.strip().rstrip(\",\") for part in parts if part.strip()]\n",
    "    return parts\n",
    "\n",
    "\n",
    "def qa_row_to_sharegpt(\n",
    "    row: pd.Series,\n",
    "    system: str = None,\n",
    "    tools: str = None,\n",
    "    question_col: str = \"question\",\n",
    "    answer_col: str = \"answer\",\n",
    "    options_col: Optional[str] = \"options\",\n",
    "    # option_choice_text = \"Please select the correct answer from the following options:\\n\",\n",
    "    option_choice_text = \"Options:\\n\",\n",
    "    post_prompt_text = \"Answer with the option's letter from the given choices directly.\",\n",
    "    full_option_answer: bool = False,\n",
    "    extras: Optional[dict] = None,  # eg {\"idx\": i}\n",
    ") -> dict:\n",
    "    \"\"\"ShareGPT FT Dataset Format\n",
    "\n",
    "    [\n",
    "    {\n",
    "        \"conversations\": [\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"user instruction\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"function_call\",\n",
    "            \"value\": \"tool arguments\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"observation\",\n",
    "            \"value\": \"tool result\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": \"model response\"\n",
    "        }\n",
    "        ],\n",
    "        \"system\": \"system prompt (optional)\",\n",
    "        \"tools\": \"tool description (optional)\"\n",
    "    }\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    # format the question with the MC options if provided\n",
    "    question = row[question_col]\n",
    "    answer = row[answer_col]\n",
    "    if options_col is not None:\n",
    "        options = row[options_col]\n",
    "        if options is None or len(options) == 0:\n",
    "            raise ValueError(f\"Options must be a non-empty list, got {options}\")\n",
    "\n",
    "        if isinstance(options, str):\n",
    "            options = parse_options(options)\n",
    "        if isinstance(options, np.ndarray):\n",
    "            options = options.tolist()\n",
    "        assert isinstance(options, list), f\"Options must be a list, got {type(options)}\"\n",
    "        assert isinstance(options[0], str), f\"Options must be a list of strings, got {type(options[0])}\"\n",
    "\n",
    "        options_str = \"\\n\".join(options)\n",
    "\n",
    "        # find the option that starts with the answer\n",
    "        correct_option = next((opt for opt in options if opt.startswith(answer)), None)\n",
    "        # override the answer with the full option if full_option_answer is True\n",
    "        if full_option_answer:\n",
    "            if correct_option is None:\n",
    "                raise ValueError(f\"No correct option found for answer {answer}\")\n",
    "            answer = correct_option\n",
    "        question = f\"{question}\\n{option_choice_text}{options_str}\\n{post_prompt_text}\"\n",
    "    elif full_option_answer:\n",
    "        raise ValueError(\"Options must be provided if full_option_answer is True\")\n",
    "\n",
    "    # format the conversation\n",
    "    conversations = []\n",
    "    conversations.append({\"from\": \"human\", \"value\": question})\n",
    "    conversations.append({\"from\": \"gpt\", \"value\": answer})\n",
    "\n",
    "    return {\n",
    "        \"conversations\": conversations,\n",
    "        **({k: v for k, v in [\n",
    "            (\"system\", system),\n",
    "            (\"tools\", tools),\n",
    "            (\"extras\", extras),\n",
    "        ] if v is not None})\n",
    "    }\n",
    "\n",
    "def bold(text: str):\n",
    "    return f\"\\033[1m{text}\\033[0m\"\n",
    "\n",
    "def pretty_print_sharegpt(entry: dict):\n",
    "    # print(json.dumps(entry, indent=2))\n",
    "    \"\"\"\n",
    "    Print it in Q:, A: format\n",
    "    \"\"\"\n",
    "    if \"system\" in entry:\n",
    "        print(f\"System: {entry['system']}\")\n",
    "    if \"tools\" in entry:\n",
    "        print(f\"Tools: {entry['tools']}\")\n",
    "    if \"extras\" in entry:\n",
    "        print(f\"Extras: {entry['extras']}\")\n",
    "    print(\"-\" * 100)\n",
    "    for conv in entry[\"conversations\"]:\n",
    "        if conv[\"from\"] == \"human\":\n",
    "            print(f\"{bold('[Q]')} {conv['value']}\")\n",
    "        elif conv[\"from\"] == \"gpt\":\n",
    "            print(f\"{bold('[A]')} {conv['value']}\")\n",
    "        elif conv[\"from\"] == \"function_call\":\n",
    "            print(f\"{bold('[Function Call]')} {conv['value']}\")\n",
    "        elif conv[\"from\"] == \"observation\":\n",
    "            print(f\"{bold('[Observation]')} {conv['value']}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown from: {conv['from']}\")\n",
    "\n",
    "\n",
    "# test it on the first row of the mmmu dataset\n",
    "row = df.iloc[0]\n",
    "entry = qa_row_to_sharegpt(row, extras={\"idx\": 0})\n",
    "print(f\"Entry: {json.dumps(entry, indent=2)}\")\n",
    "print(\"-\" * 100)\n",
    "pretty_print_sharegpt(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4196471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [00:00, 22778.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2700 entries to ../data/mmmu_sharegpt.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def df_to_sharegpt(df: pd.DataFrame, **kwargs):\n",
    "    \"\"\"\n",
    "    Convert a dataframe to a list of sharegpt entries.\n",
    "    \"\"\"\n",
    "    return [qa_row_to_sharegpt(row, *kwargs) for _, row in df.iterrows()]\n",
    "\n",
    "def df_to_sharegpt_jsonl(df: pd.DataFrame, path: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Convert a dataframe to a list of sharegpt entries and save to a jsonl file.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    # save each line as it is created, more efficient\n",
    "    with open(path, \"w\") as f:\n",
    "        for i, row in tqdm(df.iterrows()):\n",
    "            entry = qa_row_to_sharegpt(row, **kwargs, extras={\"idx\": i})\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "    print(f\"Saved {len(df)} entries to {path}\")\n",
    "\n",
    "path = \"../data/mmmu_sharegpt.jsonl\"\n",
    "df_to_sharegpt_jsonl(df, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32bc6a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2160it [00:00, 23649.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2160 entries to ../data/mmmu_sharegpt_train_80.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "540it [00:00, 23637.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 540 entries to ../data/mmmu_sharegpt_test_20.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a sample 80/20 train/test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "df_to_sharegpt_jsonl(train_df, \"../data/mmmu_sharegpt_train_80.jsonl\")\n",
    "df_to_sharegpt_jsonl(test_df, \"../data/mmmu_sharegpt_test_20.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d17ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
