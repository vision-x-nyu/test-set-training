{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsibench = load_dataset(\"nyu-visionx/VSI-Bench\")\n",
    "df = vsibench[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>1334</td>\n",
       "      <td>arkitscenes</td>\n",
       "      <td>42446103</td>\n",
       "      <td>object_rel_distance</td>\n",
       "      <td>Measuring from the closest point of each objec...</td>\n",
       "      <td>A</td>\n",
       "      <td>[A. chair, B. stool, C. stove, D. sofa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1335</td>\n",
       "      <td>arkitscenes</td>\n",
       "      <td>42446103</td>\n",
       "      <td>object_rel_distance</td>\n",
       "      <td>Measuring from the closest point of each objec...</td>\n",
       "      <td>B</td>\n",
       "      <td>[A. stove, B. table, C. stool, D. sofa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>1336</td>\n",
       "      <td>arkitscenes</td>\n",
       "      <td>42446103</td>\n",
       "      <td>object_rel_distance</td>\n",
       "      <td>Measuring from the closest point of each objec...</td>\n",
       "      <td>C</td>\n",
       "      <td>[A. chair, B. tv, C. sofa, D. stove]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      dataset scene_name        question_type  \\\n",
       "1330  1334  arkitscenes   42446103  object_rel_distance   \n",
       "1331  1335  arkitscenes   42446103  object_rel_distance   \n",
       "1332  1336  arkitscenes   42446103  object_rel_distance   \n",
       "\n",
       "                                               question ground_truth  \\\n",
       "1330  Measuring from the closest point of each objec...            A   \n",
       "1331  Measuring from the closest point of each objec...            B   \n",
       "1332  Measuring from the closest point of each objec...            C   \n",
       "\n",
       "                                      options  \n",
       "1330  [A. chair, B. stool, C. stove, D. sofa]  \n",
       "1331  [A. stove, B. table, C. stool, D. sofa]  \n",
       "1332     [A. chair, B. tv, C. sofa, D. stove]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf = df[df[\"question_type\"] == \"object_rel_distance\"].copy()\n",
    "qdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Measuring from the closest point of each object, which of these objects (refrigerator, bed, window, trash bin) is the closest to the door?',\n",
       "       'Measuring from the closest point of each object, which of these objects (whiteboard, table, heater, chair) is the closest to the telephone?',\n",
       "       'Measuring from the closest point of each object, which of these objects (table, cushion, sofa, clock) is the closest to the door?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf[\"question\"].sample(3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Extract Target and GT Object Name ---\n",
    "# Extract target object (last object mentioned in question)\n",
    "qdf[[\"object_1\", \"object_2\", \"object_3\", \"object_4\", \"target_object\"]] = qdf[\"question\"].str.extract(r'which of these objects \\((.*?), (.*?), (.*?), (.*?)\\) is the closest to the (.*?)\\?$')\n",
    "\n",
    "# Extract GT object name from options\n",
    "qdf[\"gt_idx\"] = qdf[\"ground_truth\"].apply(lambda x: \"ABCD\".index(x))\n",
    "qdf[\"gt_option\"] = qdf.apply(lambda row: row[\"options\"][row[\"gt_idx\"]], axis=1)\n",
    "# Ensure no leading/trailing spaces in gt object name\n",
    "qdf[\"gt_object\"] = qdf[\"gt_option\"].apply(lambda x: x.split(\". \")[-1].strip())\n",
    "\n",
    "qdf[\"tgt_gt_pair\"] = qdf.apply(lambda row: \"-\".join(sorted([row[\"target_object\"], row[\"gt_object\"]])), axis=1)\n",
    "qdf[\"tgt_gt_ord_pair\"] = qdf.apply(lambda row: \"-\".join([row[\"target_object\"], row[\"gt_object\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1.  Helper that injects frequency features, given training‑set counts\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def add_frequency_features(df: pd.DataFrame,\n",
    "                            gt_obj_counts: pd.Series,\n",
    "                            global_pair_counts: pd.Series,\n",
    "                            global_ordered_pair_counts: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Return *new* DataFrame with leakage‑free frequency features added.\"\"\"\n",
    "    df = df.copy()\n",
    "    for i in range(4):\n",
    "        df[f\"opt_{i}_option_freq\"] = df[f\"object_{i+1}\"].map(gt_obj_counts).fillna(0)\n",
    "        df[f\"opt_{i}_tgt_option_pair_freq\"] = df[\"tgt_gt_pair\"].map(global_pair_counts).fillna(0)\n",
    "        df[f\"opt_{i}_tgt_option_ord_pair_freq\"] = df[\"tgt_gt_ord_pair\"].map(global_ordered_pair_counts).fillna(0)\n",
    "\n",
    "    df[\"max_option_freq\"] = df[[f\"opt_{i}_option_freq\" for i in range(4)]].max(axis=1)\n",
    "    df[\"max_tgt_option_pair_freq\"] = df[[f\"opt_{i}_tgt_option_pair_freq\" for i in range(4)]].max(axis=1)\n",
    "    df[\"max_tgt_option_ord_pair_freq\"] = df[[f\"opt_{i}_tgt_option_ord_pair_freq\" for i in range(4)]].max(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Added for mean/std calculation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer # Added make_scorer for cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score # Added KFold and cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "feature_cols = [\n",
    "    'object_1', 'object_2', 'object_3', 'object_4', 'target_object',\n",
    "    # 'option_prob', 'tgt_option_pair_prob', 'tgt_option_ord_pair_prob'\n",
    "    'max_option_freq',\n",
    "    'max_tgt_option_pair_freq', 'max_tgt_option_ord_pair_freq',\n",
    "    'opt_0_option_freq', 'opt_0_tgt_option_pair_freq',\n",
    "    'opt_0_tgt_option_ord_pair_freq', 'opt_1_option_freq',\n",
    "    'opt_1_tgt_option_pair_freq', 'opt_1_tgt_option_ord_pair_freq',\n",
    "    'opt_2_option_freq', 'opt_2_tgt_option_pair_freq',\n",
    "    'opt_2_tgt_option_ord_pair_freq', 'opt_3_option_freq',\n",
    "    'opt_3_tgt_option_pair_freq', 'opt_3_tgt_option_ord_pair_freq'\n",
    "]\n",
    "target_col = \"ground_truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: accuracy = 0.3803\n",
      "Fold 2: accuracy = 0.3310\n",
      "Fold 3: accuracy = 0.4085\n",
      "Fold 4: accuracy = 0.3732\n",
      "Fold 5: accuracy = 0.4014\n",
      "\n",
      "Overall: 0.3789 ± 0.0272 (n_splits=5)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_rf_bias_cv_no_leak(df: pd.DataFrame, n_splits: int = 5,\n",
    "                                feature_cols=feature_cols,\n",
    "                                target_col: str = target_col,\n",
    "                                random_state: int = 42):\n",
    "    \"\"\"Return mean ± std accuracy of an RF trained with leakage‑free freq features.\"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(df, df[target_col]), 1):\n",
    "        train_df = df.iloc[train_idx].copy()\n",
    "        test_df  = df.iloc[test_idx].copy()\n",
    "\n",
    "        # --- (i)  Re‑compute counts from TRAIN ONLY --------------------------\n",
    "        gt_obj_counts = train_df[\"gt_object\"].value_counts()\n",
    "        global_pair_counts = train_df[\"tgt_gt_pair\"].value_counts()\n",
    "        global_ordered_pair_counts = train_df[\"tgt_gt_ord_pair\"].value_counts()\n",
    "\n",
    "        # --- (ii) Add leakage‑free freq features -----------------------------\n",
    "        train_df = add_frequency_features(train_df, gt_obj_counts,\n",
    "                                          global_pair_counts, global_ordered_pair_counts)\n",
    "        test_df  = add_frequency_features(test_df,  gt_obj_counts,\n",
    "                                          global_pair_counts, global_ordered_pair_counts)\n",
    "\n",
    "        # --- (iii) Encode categorical columns --------------------------------\n",
    "        X_train, X_test = train_df[feature_cols].copy(), test_df[feature_cols].copy()\n",
    "        cat_cols = X_train.select_dtypes(include=\"object\").columns\n",
    "        encoders = {}\n",
    "        for col in cat_cols:\n",
    "            enc = LabelEncoder().fit(pd.concat([X_train[col], X_test[col]], axis=0).astype(str))\n",
    "            X_train[col] = enc.transform(X_train[col].astype(str))\n",
    "            X_test[col]  = enc.transform(X_test[col].astype(str))\n",
    "            encoders[col] = enc\n",
    "\n",
    "        y_train, y_test = train_df[target_col], test_df[target_col]\n",
    "\n",
    "        # --- (iv) Fit + evaluate --------------------------------------------\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        scores.append(acc)\n",
    "        print(f\"Fold {fold}: accuracy = {acc:.4f}\")\n",
    "\n",
    "    mean_acc, std_acc = np.mean(scores), np.std(scores)\n",
    "    print(f\"\\nOverall: {mean_acc:.4f} ± {std_acc:.4f} (n_splits={n_splits})\")\n",
    "    return mean_acc, std_acc\n",
    "\n",
    "evaluate_rf_bias_cv_no_leak(qdf, n_splits=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds: 100%|██████████| 5/5 [00:00<00:00,  9.44it/s, avg_acc=37.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall: 37.89% ± 2.72% (n_splits=5)\n",
      "Scores for each fold: [0.38028169014084506, 0.33098591549295775, 0.4084507042253521, 0.3732394366197183, 0.4014084507042254]\n",
      "\n",
      "Training final model on all data to get feature importances…\n",
      "\n",
      "Feature Importances (from final model trained on all data):\n",
      "                           feature  importance\n",
      "0                opt_2_option_freq    0.086204\n",
      "1                opt_3_option_freq    0.084059\n",
      "2                opt_1_option_freq    0.082356\n",
      "3                         object_1    0.078862\n",
      "4                opt_0_option_freq    0.076571\n",
      "5                    target_object    0.076182\n",
      "6                         object_2    0.075562\n",
      "7                         object_3    0.075552\n",
      "8                         object_4    0.075303\n",
      "9                  max_option_freq    0.038726\n",
      "10        max_tgt_option_pair_freq    0.029416\n",
      "11  opt_2_tgt_option_ord_pair_freq    0.026300\n",
      "12      opt_1_tgt_option_pair_freq    0.026260\n",
      "13      opt_2_tgt_option_pair_freq    0.026083\n",
      "14      opt_3_tgt_option_pair_freq    0.025162\n",
      "15      opt_0_tgt_option_pair_freq    0.024928\n",
      "16    max_tgt_option_ord_pair_freq    0.023725\n",
      "17  opt_0_tgt_option_ord_pair_freq    0.023610\n",
      "18  opt_1_tgt_option_ord_pair_freq    0.022892\n",
      "19  opt_3_tgt_option_ord_pair_freq    0.022247\n"
     ]
    }
   ],
   "source": [
    "def evaluate_rf_bias_cv_no_leak(df: pd.DataFrame, n_splits: int = 5,\n",
    "                                feature_cols=feature_cols,\n",
    "                                target_col: str = target_col,\n",
    "                                random_state: int = 42):\n",
    "    \"\"\"Return mean ± std accuracy and a DataFrame of RF feature importances.\"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    scores = []\n",
    "\n",
    "    pbar = tqdm(enumerate(skf.split(df, df[target_col]), 1), total=n_splits, desc=\"CV Folds\")\n",
    "    for fold, (train_idx, test_idx) in pbar:\n",
    "        train_df, test_df = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()\n",
    "\n",
    "        # (i) Re‑compute counts on *train* only ------------------------------\n",
    "        gt_counts   = train_df[\"gt_object\"].value_counts()\n",
    "        pair_counts = train_df[\"tgt_gt_pair\"].value_counts()\n",
    "        ord_counts  = train_df[\"tgt_gt_ord_pair\"].value_counts()\n",
    "\n",
    "        # (ii) Inject leakage‑free features ---------------------------------\n",
    "        train_df = add_frequency_features(train_df, gt_counts, pair_counts, ord_counts)\n",
    "        test_df  = add_frequency_features(test_df,  gt_counts, pair_counts, ord_counts)\n",
    "\n",
    "        # (iii) Encode categoricals -----------------------------------------\n",
    "        X_train, X_test = train_df[feature_cols].copy(), test_df[feature_cols].copy()\n",
    "        cat_cols = X_train.select_dtypes(include='object').columns\n",
    "        encoders = {}\n",
    "        for col in cat_cols:\n",
    "            enc = LabelEncoder().fit(pd.concat([X_train[col], X_test[col]], axis=0).astype(str))\n",
    "            X_train[col] = enc.transform(X_train[col].astype(str))\n",
    "            X_test[col]  = enc.transform(X_test[col].astype(str))\n",
    "            encoders[col] = enc\n",
    "\n",
    "        y_train, y_test = train_df[target_col], test_df[target_col]\n",
    "\n",
    "        # (iv) Fit and evaluate --------------------------------------------\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        scores.append(acc)\n",
    "        pbar.set_postfix({\"avg_acc\": f\"{np.mean(scores):.2%}\"})\n",
    "\n",
    "    mean_acc, std_acc = np.mean(scores), np.std(scores)\n",
    "    print(f\"\\nOverall: {mean_acc:.2%} ± {std_acc:.2%} (n_splits={n_splits})\")\n",
    "    print(f\"Scores for each fold: {scores}\")\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 3.  Train final model on *all* data for feature importances (OK to see all rows)\n",
    "    # ---------------------------------------------------------------------\n",
    "    print(\"\\nTraining final model on all data to get feature importances…\")\n",
    "    full_gt_counts   = df['gt_object'].value_counts()\n",
    "    full_pair_counts = df['tgt_gt_pair'].value_counts()\n",
    "    full_ord_counts  = df['tgt_gt_ord_pair'].value_counts()\n",
    "\n",
    "    full_df = add_frequency_features(df, full_gt_counts, full_pair_counts, full_ord_counts)\n",
    "\n",
    "    X_full = full_df[feature_cols].copy()\n",
    "    y_full = full_df[target_col]\n",
    "\n",
    "    cat_cols = X_full.select_dtypes(include='object').columns\n",
    "    for col in cat_cols:\n",
    "        enc = LabelEncoder().fit(X_full[col].astype(str))\n",
    "        X_full[col] = enc.transform(X_full[col].astype(str))\n",
    "\n",
    "    final_model = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "    final_model.fit(X_full, y_full)\n",
    "\n",
    "    feature_importance_df = (\n",
    "        pd.DataFrame({\n",
    "            'feature': X_full.columns,\n",
    "            'importance': final_model.feature_importances_\n",
    "        })\n",
    "        .sort_values('importance', ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\nFeature Importances (from final model trained on all data):\")\n",
    "    print(feature_importance_df)\n",
    "\n",
    "    return mean_acc, std_acc, feature_importance_df\n",
    "\n",
    "evaluate_rf_bias_cv_no_leak(qdf, n_splits=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds: 100%|██████████| 50/50 [00:05<00:00,  9.33it/s, avg_acc=39.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall: 39.42% ± 11.81% (n_splits=50)\n",
      "Scores for each fold: [0.4666666666666667, 0.4, 0.3333333333333333, 0.4666666666666667, 0.4, 0.4666666666666667, 0.3333333333333333, 0.4, 0.4, 0.4, 0.35714285714285715, 0.21428571428571427, 0.35714285714285715, 0.35714285714285715, 0.35714285714285715, 0.2857142857142857, 0.35714285714285715, 0.35714285714285715, 0.21428571428571427, 0.2857142857142857, 0.5, 0.5714285714285714, 0.6428571428571429, 0.5714285714285714, 0.35714285714285715, 0.2857142857142857, 0.2857142857142857, 0.5, 0.5714285714285714, 0.2857142857142857, 0.35714285714285715, 0.7142857142857143, 0.5, 0.2857142857142857, 0.35714285714285715, 0.21428571428571427, 0.42857142857142855, 0.14285714285714285, 0.5, 0.5, 0.2857142857142857, 0.5714285714285714, 0.5714285714285714, 0.2857142857142857, 0.35714285714285715, 0.35714285714285715, 0.2857142857142857, 0.35714285714285715, 0.5, 0.35714285714285715]\n",
      "\n",
      "Training final model on all data to get feature importances…\n",
      "\n",
      "Feature Importances (from final model trained on all data):\n",
      "                           feature  importance\n",
      "0                opt_2_option_freq    0.086204\n",
      "1                opt_3_option_freq    0.084059\n",
      "2                opt_1_option_freq    0.082356\n",
      "3                         object_1    0.078862\n",
      "4                opt_0_option_freq    0.076571\n",
      "5                    target_object    0.076182\n",
      "6                         object_2    0.075562\n",
      "7                         object_3    0.075552\n",
      "8                         object_4    0.075303\n",
      "9                  max_option_freq    0.038726\n",
      "10        max_tgt_option_pair_freq    0.029416\n",
      "11  opt_2_tgt_option_ord_pair_freq    0.026300\n",
      "12      opt_1_tgt_option_pair_freq    0.026260\n",
      "13      opt_2_tgt_option_pair_freq    0.026083\n",
      "14      opt_3_tgt_option_pair_freq    0.025162\n",
      "15      opt_0_tgt_option_pair_freq    0.024928\n",
      "16    max_tgt_option_ord_pair_freq    0.023725\n",
      "17  opt_0_tgt_option_ord_pair_freq    0.023610\n",
      "18  opt_1_tgt_option_ord_pair_freq    0.022892\n",
      "19  opt_3_tgt_option_ord_pair_freq    0.022247\n"
     ]
    }
   ],
   "source": [
    "evaluate_rf_bias_cv_no_leak(qdf, n_splits=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds: 100%|██████████| 100/100 [00:10<00:00,  9.22it/s, avg_acc=38.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall: 38.23% ± 17.76% (n_splits=100)\n",
      "Scores for each fold: [0.5, 0.5, 0.5, 0.25, 0.5, 0.5, 0.25, 0.25, 0.625, 0.5, 0.42857142857142855, 0.14285714285714285, 0.5714285714285714, 0.14285714285714285, 0.5714285714285714, 0.5714285714285714, 0.42857142857142855, 0.7142857142857143, 0.42857142857142855, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.2857142857142857, 0.5714285714285714, 0.42857142857142855, 0.14285714285714285, 0.42857142857142855, 0.5714285714285714, 0.7142857142857143, 0.2857142857142857, 0.0, 0.42857142857142855, 0.14285714285714285, 0.14285714285714285, 0.42857142857142855, 0.5714285714285714, 0.14285714285714285, 0.2857142857142857, 0.14285714285714285, 0.5714285714285714, 0.2857142857142857, 0.5714285714285714, 0.14285714285714285, 0.42857142857142855, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.5714285714285714, 0.5714285714285714, 0.2857142857142857, 0.2857142857142857, 0.5714285714285714, 0.42857142857142855, 0.2857142857142857, 0.7142857142857143, 0.42857142857142855, 0.5714285714285714, 0.2857142857142857, 0.5714285714285714, 0.8571428571428571, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.0, 0.42857142857142855, 0.14285714285714285, 0.2857142857142857, 0.42857142857142855, 0.2857142857142857, 0.5714285714285714, 0.42857142857142855, 0.42857142857142855, 0.0, 0.42857142857142855, 0.2857142857142857, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.2857142857142857, 0.5714285714285714, 0.42857142857142855, 0.42857142857142855, 0.5714285714285714, 0.7142857142857143, 0.14285714285714285, 0.42857142857142855, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.42857142857142855, 0.42857142857142855, 0.7142857142857143, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857]\n",
      "\n",
      "Training final model on all data to get feature importances…\n",
      "\n",
      "Feature Importances (from final model trained on all data):\n",
      "                           feature  importance\n",
      "0                opt_2_option_freq    0.086204\n",
      "1                opt_3_option_freq    0.084059\n",
      "2                opt_1_option_freq    0.082356\n",
      "3                         object_1    0.078862\n",
      "4                opt_0_option_freq    0.076571\n",
      "5                    target_object    0.076182\n",
      "6                         object_2    0.075562\n",
      "7                         object_3    0.075552\n",
      "8                         object_4    0.075303\n",
      "9                  max_option_freq    0.038726\n",
      "10        max_tgt_option_pair_freq    0.029416\n",
      "11  opt_2_tgt_option_ord_pair_freq    0.026300\n",
      "12      opt_1_tgt_option_pair_freq    0.026260\n",
      "13      opt_2_tgt_option_pair_freq    0.026083\n",
      "14      opt_3_tgt_option_pair_freq    0.025162\n",
      "15      opt_0_tgt_option_pair_freq    0.024928\n",
      "16    max_tgt_option_ord_pair_freq    0.023725\n",
      "17  opt_0_tgt_option_ord_pair_freq    0.023610\n",
      "18  opt_1_tgt_option_ord_pair_freq    0.022892\n",
      "19  opt_3_tgt_option_ord_pair_freq    0.022247\n"
     ]
    }
   ],
   "source": [
    "evaluate_rf_bias_cv_no_leak(qdf, n_splits=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm_debias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
